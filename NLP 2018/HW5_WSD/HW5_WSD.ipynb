{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "from pprint import pprint\n",
    "from pymystem3 import Mystem\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'со', 'по', 'не', 'на', 'что', 'каждый', 'пока', 'здесь', 'этот', 'во', 'едва', 'примечательно', 'главный', 'без', 'над', 'ещё', 'рамка', 'с', 'восемь', 'по-прежнему', 'самый', 'стать', 'год', 'я', 'четыре', 'даже', 'в', 'уже', 'она', 'первый', 'еще', 'после', 'он', 'и', 'свой', 'лишь', 'а', 'два', 'ли'}\n"
     ]
    }
   ],
   "source": [
    "def load_stop_words(stop_filename):\n",
    "\t''' загрузить список стоп-слов из файла, одно слово на строке '''\n",
    "\twith open(stop_filename, encoding = 'utf-8') as f:\n",
    "\t\tstopwords = [w.strip() for w in f.readlines()]\n",
    "\treturn set(stopwords)\n",
    "\n",
    "stop_words = load_stop_words(\"stoplist_russian.txt\")\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "def preprocessing(raw_text):\n",
    "    clean_text = re.sub('\\W+', ' ', raw_text) # \\W = [^a-zA-Z0-9_]\n",
    "    return clean_text\n",
    "\n",
    "def lemmatize(input):\n",
    "    return [lemma.strip() for lemma in m.lemmatize(preprocessing(input.lower())) if lemma.strip()]\n",
    "\n",
    "def remove_stop_words(lemmas, stopwords):\n",
    "    return ' '.join([word for word in lemmas if word not in stopwords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве корпуса мы возьмем два файла, каждый из которых включает примерно 7000-1000 контекстов со словом \"язык\".\n",
    "Каждый контекст написан на новой строке. Примеры из файла language.txt (контексты со значением \"орган\") получают значение \"0\", а из файла tongue.txt (контексты со значением как в сочетании \"русский язык\") значение 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "725"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = pd.read_csv(\"language2.csv\", header=None)\n",
    "language = list(language[0].values)\n",
    "len(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sent in enumerate(language):\n",
    "    language[i] = [0, remove_stop_words(lemmatize(preprocessing(language[i])), stop_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 'трудно даваться математика русский рваться сюда суббота'],\n",
       " [0, 'широкий пасть задний дверь вывалиться аппарель гроб скользнуть'],\n",
       " [0, 'касание к небо игорь переключать воспроизведение'],\n",
       " [0,\n",
       "  'навстречу слюнявый пасть приветственный вывалить радостно помахивать хвост'],\n",
       " [0, 'удерживаться лизнуть шершавый мордочка любимая видеть темный'],\n",
       " [0,\n",
       "  'оказываться необходимый чтобы говорить публицистический который данный случай'],\n",
       " [0,\n",
       "  'весь сводка опубликовывать французский отсутствовать точный координата станция баро'],\n",
       " [0, 'огромный черный весь время вываливаться изо рот'],\n",
       " [0, 'поблескивать как пуговка черный то дело вываливаться изо'],\n",
       " [0, 'италия где давать урок греческий петрарка']]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tongue = pd.read_csv(\"tongue2.csv\", header=None, delimiter=';')\n",
    "tongue = list(tongue[0].values)\n",
    "len(tongue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sent in enumerate(tongue):\n",
    "    tongue[i] = sent.lower()\n",
    "    tongue[i] = re.sub(' язык.*?( |$)', ' ', sent)\n",
    "    tongue[i] = [1, remove_stop_words(lemmatize(preprocessing(tongue[i])), stop_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'сила оставаться только копченый олений'],\n",
       " [1, 'филе пулярка устрица жареный бараний язык соус рамолад куриный'],\n",
       " [1, 'бутылка пиво корона вытрясать розовый язык светлый капля'],\n",
       " [1,\n",
       "  'давать сигнал мышца ротовой полость гибкий язык передвигать подсолнух к коренной'],\n",
       " [1,\n",
       "  'липкий бумажка разевать рот облизывать красный язык сладкий игольчатый холодок'],\n",
       " [1, 'движение воздух вытягивать собачий язык вызывать дыхание который'],\n",
       " [1, 'выглядывать красный глазок высовываться ржавый'],\n",
       " [1, 'мститель лаэрт фехтовальщик кончик красный язык который так легко'],\n",
       " [1,\n",
       "  'медведь дарья зуб оскаливать высовывать красный язык вытягивать лапа коготь'],\n",
       " [1, 'длинный железный коготь долгий огненный язык']]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tongue[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = language + tongue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление корпуса и автоматическая классификация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# математика\n",
    "import numpy as np\n",
    "\n",
    "# разные классификаторы\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# векторизация\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# деление корпуса train/test\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [item[1] for item in data]\n",
    "y = [item[0] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('SVM', LinearSVC), ('Bayes', MultinomialNB), ('Forest', RandomForestClassifier)]\n",
    "vectorizers = [('CV', CountVectorizer), ('TfIdf', TfidfVectorizer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_classifier(clf, metric='f1', data=X):\n",
    "    scores = cross_val_score(pipeline, np.asarray(data), np.asarray(y), cv=5, scoring=metric)\n",
    "    score = sum(scores) / len(scores)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for clf in classifiers:\n",
    "    for vctr in vectorizers:\n",
    "        pipeline = Pipeline([\n",
    "    ('vectorizer', vctr[1]()),\n",
    "    ('classifier', clf[1]()) ])\n",
    "        scores.append((clf[0], vctr[0], score_classifier(pipeline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Forest', 'TfIdf', 0.8210713982865887),\n",
       " ('Forest', 'CV', 0.8354139810412422),\n",
       " ('SVM', 'CV', 0.8757884122655021),\n",
       " ('SVM', 'TfIdf', 0.9027268507743089),\n",
       " ('Bayes', 'TfIdf', 0.9243984636476889),\n",
       " ('Bayes', 'CV', 0.9305478962864122)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort(key=lambda tup: tup[2])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество f1_score дает комбинация Count Vectorizer и Наивного Байевского классификатора - 0.93."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426, 3771)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_vectorizer = CountVectorizer()\n",
    "cv = cv_vectorizer.fit_transform(X)\n",
    "cv = cv.toarray()\n",
    "cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "cv_pca = pca.fit_transform(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1426, 1426) (1426,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(cv_pca.shape, y.shape)\n",
    "print(type(cv_pca), type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cv_pca, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108433734939759"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cv = LinearSVC()\n",
    "clf_cv.fit(X_train, y_train)\n",
    "y_pred_cv = clf_cv.predict(X_test)\n",
    "f1_score(y_test, y_pred_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для уменьшения размерности используем метод главных компонент PCA. Количество признаков уменьшилось с 3771 до 1426.\n",
    "Качество модели LinearSVC с векторным представлением Count Vectorizer увеличилось на 0.35 и стало выше 0.9."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
