# Word Sense Disambiguation

## Цель
Для некоторого многозначного слова научится предсказывать его значение в контексте.  

## Задача
Оценить качество работы различных классификаторов и векторайзеров на примере предсказания значения слова **язык**.  

## Материал  

Данные состоят из двух частей. В первой (файл language.csv) собраны контексты слова **язык** в значении *язык, на котором говорят*. Во второй (файл tongue.csv) - контексты слова **язык** в значении *орган человека*.
Все контексты взяты из Национального Корпуса Русского языка (www.ruscorpora.ru). Данные были отбраны вручную из вхождений по запросу "язык" по всем подкорпусам корпуса. Контексты со значением *орган человека* также отбирались отдельно по запросам *прилагательное с семантикой физического свойства + язык* и *предлог+язык*.

Параметры:  
Окно +-5.  
Объём language.csv: 725 контекстов, 6000 слов  
Объём tongue.csv: 701 контекст, 6300 слов

В файле mycontexts.csv лежит по 5 придуманных контекстов на каждое значение.

## Предобработка  

•	удаление пунктуации  
•	приведение к нижнему регистру  
•	токенизация  
•	лемматизация  
•	удаление стоп-слов (файл stoplist_russian.txt)  

## Векторайзеры  
Векторайзеры реализованы с помощью библиотеки Scikit-learn  
•	CountVectorizer  
•	TfidfVectorizer  

## Классификаторы  
Классификаторы реализованы с помощью библиотеки Scikit-learn  
•	LinearSVC  
•	MultinomialNB  
•	RandomForestClassifier  

**Таблица 1. F1-score 7 различных моделей**

-|SVM|SVM_PCA|Forest|Bayes  
-|---|-------|------|-----  
CV|0.88|0.91|0.82|0.93  
TfIdf|0.90|-|0.82|0.92  

Для уменьшения размерности используем метод главных компонент PCA. Количество признаков уменьшилось с 3771 до 1426. Качество модели LinearSVC с векторным представлением Count Vectorizer увеличилось на 0.35 и стало выше 0.9. Модель все еще работает не идеально, допускаются ошибки (см. таблицу 2). Улушчить качество модели можно подобрав лучшее значения параметра C (коэффициент регуляризации) с помощью GridSearch.   

**Таблица 2. Примеры ошибочных предсказаний модели LinearSVC **

context|true|predict  
-------|----|-------


Лучшее качество f1_score дает комбинация Count Vectorizer и Наивного Байевского классификатора - 0.93.  
Оценим качество лучшей модели на 10 собственных примерах (файл mycontexts.csv):

**Таблица 3. Оценка качества модели Count Vectorizer + MultinomialNB **
  
context|true|predict  
-------|----|-------  
Я говорю на десяти в совершенстве|0|0  
Мелофон позволяет понимать животных|0|0  
Он выражался на непонятном мне змеином|0|0  
Данте гораздо сложнее понимать, чем современный итальянский|0|0  
Я хочу выучить французский, чтобы поехать учиться во Францию|0|0  
Врач сделал укол, и мой онемел|1|1  
Собака высунула кончик языка и завиляла хвостом|1|1  
Мальчик показывал однокласснице, и учитель написал ему замечание|`1`|`0`  
Зловещно извивались развдоенные змеиные|`1`|`0`  
Не облизывай губы на морозе|`1`|`0`  

f1-score = 0.57  
Все контексты в первом значении модель распознает верно, но контексты второго значения относит в 3 из 5 случаев к первому классу.  
Возможные проблемы:  
- *Змеиные языки* может относиться, как к первому классу, так и ко второму в обучающей выборке  
- *учитель* может часто встречаться в контексте языка, которому учат  
